{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensor import Tensor, Dependency, add\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = Tensor([1, 2, 3], requires_grad=True)\n",
    "t2 = t1.sum()\n",
    "t2.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ones_like([1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(np.array([1, 1]), np.ndarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_fn(grad: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"grad is necessarily a 0-tensor, so each input element contributes that much\"\"\"\n",
    "    return grad * np.ones_like([3, 3, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = Tensor([3.0, 2.0, 4.0], requires_grad=True)\n",
    "t2 = Tensor([3.0, 3.0, 3.0], requires_grad=True)\n",
    "t3 = Tensor([3.0, 3.0, 3.0], requires_grad=True, depends_on=[Dependency(t1, grad_fn)])\n",
    "t4 = Tensor([3.0, 3.0, 3.0], requires_grad=True, depends_on=[Dependency(t2, grad_fn)])\n",
    "t5 = Tensor(\n",
    "    [3.0, 3.0, 3.0],\n",
    "    requires_grad=True,\n",
    "    depends_on=[Dependency(t3, grad_fn), Dependency(t4, grad_fn)],\n",
    ")\n",
    "t6 = Tensor(\n",
    "    [3.0, 3.0, 3.0],\n",
    "    requires_grad=True,\n",
    "    depends_on=[Dependency(t2, grad_fn), Dependency(t5, grad_fn)],\n",
    ")\n",
    "t7 = Tensor(\n",
    "    [3.0, 3.0, 3.0],\n",
    "    requires_grad=True,\n",
    "    depends_on=[Dependency(t6, grad_fn), Dependency(t5, grad_fn)],\n",
    ")\n",
    "t7.backward(Tensor([9, 9, 9]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor([18. 18. 18.], requires_grad=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t5.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(9.0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t7.data.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor([[4 5]\n",
       " [7 8]], requires_grad=True)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = Tensor(np.array([[1], [2]]), requires_grad=True)  # Shape (2,1)\n",
    "t2 = Tensor(np.array([[3, 4], [5, 6]]), requires_grad=True)  # Shape (2,2)\n",
    "\n",
    "result = add(t1, t2)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = Tensor([1, 2, 3], requires_grad=True)\n",
    "t2 = Tensor(10, requires_grad=True)  # Scalar\n",
    "t3 = add(t1, t2)\n",
    "t3.backward(Tensor([1, 1, 1]))  # Passing a gradient of [1, 1, 1]\n",
    "\n",
    "t2.grad.data.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def make_grad_fn(\n",
    "    original_shape: tuple, other_data: np.ndarray, chain_rule_fn: Callable\n",
    ") -> Callable[[np.ndarray], np.ndarray]:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        original_shape: Shape of the Tensor.\n",
    "        other_data: Other Tensor data.\n",
    "        chain_rule_fn: Function that takes (grad, other_data) and returns modified grad.\n",
    "        example: chain_rule_fn = lambda g, x: g * x <-- multiplication chain rule\n",
    "    \"\"\"\n",
    "\n",
    "    def grad_fn(grad: np.ndarray) -> np.ndarray:\n",
    "        grad = chain_rule_fn(grad, other_data)\n",
    "\n",
    "        if grad.shape != original_shape:\n",
    "            # Identify all axes that were either:\n",
    "            # 1. Added in forward pass (not in original shape), OR\n",
    "            # 2. Were size-1 in original (and thus broadcasted)\n",
    "            sum_axes = [\n",
    "                i\n",
    "                for i in range(-1, -len(grad.shape) - 1, -1)\n",
    "                if (i < -len(original_shape))  # Added dimension\n",
    "                or (original_shape[i] == 1)  # Broadcasted dimension\n",
    "            ]\n",
    "\n",
    "            if sum_axes:\n",
    "                grad = grad.sum(axis=tuple(sum_axes), keepdims=True)\n",
    "\n",
    "            # Remove any extra dimensions that summing didn't handle\n",
    "            if grad.ndim > len(original_shape):\n",
    "                grad = grad.reshape(original_shape)\n",
    "\n",
    "        return grad\n",
    "\n",
    "    return grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_shape = (3,)\n",
    "other_data = ()\n",
    "\n",
    "\n",
    "def chain_rule_fn(g, x):\n",
    "    return g\n",
    "\n",
    "\n",
    "def grad_fn(grad: np.ndarray) -> np.ndarray:\n",
    "    grad = chain_rule_fn(grad, other_data)\n",
    "\n",
    "    if grad.shape != original_shape:\n",
    "        # Identify all axes that were either:\n",
    "        # 1. Added in forward pass (not in original shape), OR\n",
    "        # 2. Were size-1 in original (and thus broadcasted)\n",
    "        print(grad.shape, original_shape)\n",
    "        sum_axes = [\n",
    "            i\n",
    "            for i in range(-1, -len(grad.shape) - 1, -1)\n",
    "            if (i < -len(original_shape))  # Added dimension\n",
    "            or (original_shape[i] == 1)  # Broadcasted dimension\n",
    "        ]\n",
    "        print(sum_axes)\n",
    "        if sum_axes:\n",
    "            grad = grad.sum(axis=tuple(sum_axes), keepdims=True)\n",
    "        # Remove any extra dimensions that summing didn't handle\n",
    "        if grad.ndim > len(original_shape):\n",
    "            grad = grad.reshape(original_shape)\n",
    "        print(grad)\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3, 3) (3,)\n",
      "[-2, -3]\n",
      "[[[27 27 27]]]\n",
      "[27 27 27]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([27, 27, 27])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad = grad_fn(\n",
    "    np.array(\n",
    "        [\n",
    "            [[3, 3, 3], [3, 3, 3], [3, 3, 3]],\n",
    "            [[3, 3, 3], [3, 3, 3], [3, 3, 3]],\n",
    "            [[3, 3, 3], [3, 3, 3], [3, 3, 3]],\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "grad"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
